{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"digits_speach_record.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPsrCVNVjIzUadytPHksERS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# IMPORT PACKAGES\n","All package that are imported for the solution of the problem"],"metadata":{"id":"wY2ROtMgAb98"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"j2uKVtPYcNwG","executionInfo":{"status":"ok","timestamp":1648903928166,"user_tz":-120,"elapsed":6390,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}}},"outputs":[],"source":["import random\n","import torch\n","import torch.nn as nn\n","from torch.nn import init\n","import torchaudio\n","from torchaudio import transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from google.colab import drive"]},{"cell_type":"code","source":["#@title Prepare utilities for sound functions. {display-mode: \"form\"}\n","#@markdown\n","#@markdown You do not need to look into this cell.\n","#@markdown Just execute once and you are good to go.\n","\n","#-------------------------------------------------------------------------------\n","# Preparation of data and helper functions.\n","#-------------------------------------------------------------------------------\n","\n","class SoundUtils():\n","  \n","  @staticmethod\n","  def open(audio_file):\n","    sig, sr = torchaudio.load(audio_file)\n","    return (sig, sr)\n","\n","  @staticmethod\n","  def rechannel(aud, new_channel):\n","    sig, sr = aud\n","    if (sig.shape[0] == new_channel):\n","      return aud\n","    if (new_channel == 1):\n","      resig = sig[:1, :]\n","    else:\n","      resig = torch.cat([sig, sig])\n","    return ((resig, sr))\n","\n","  @staticmethod\n","  def resample(aud, newsr):\n","    sig, sr = aud\n","    if (sr == newsr):\n","      return aud\n","    num_channels = sig.shape[0]\n","    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n","    if (num_channels > 1):\n","      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n","      resig = torch.cat([resig, retwo])\n","    return ((resig, newsr))\n","\n","  @staticmethod\n","  def pad_trunc(aud, max_ms):\n","    sig, sr = aud\n","    num_rows, sig_len = sig.shape\n","    max_len = sr//1000 * max_ms\n","\n","    if (sig_len > max_len):\n","      sig = sig[:,:max_len]\n","\n","    elif (sig_len < max_len):\n","      pad_begin_len = random.randint(0, max_len - sig_len)\n","      pad_end_len = max_len - sig_len - pad_begin_len\n","      pad_begin = torch.zeros((num_rows, pad_begin_len))\n","      pad_end = torch.zeros((num_rows, pad_end_len))\n","      sig = torch.cat((pad_begin, sig, pad_end), 1)\n","    return (sig, sr)\n","\n","  @staticmethod\n","  def time_shift(aud, shift_limit):\n","    sig,sr = aud\n","    _, sig_len = sig.shape\n","    shift_amt = int(random.random() * shift_limit * sig_len)\n","    return (sig.roll(shift_amt), sr)\n","\n","  @staticmethod\n","  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n","    sig,sr = aud\n","    top_db = 80\n","    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n","    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n","    return (spec)\n","  \n","  @staticmethod\n","  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n","    _, n_mels, n_steps = spec.shape\n","    mask_value = spec.mean()\n","    aug_spec = spec\n","\n","    freq_mask_param = max_mask_pct * n_mels\n","    for _ in range(n_freq_masks):\n","      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n","\n","    time_mask_param = max_mask_pct * n_steps\n","    for _ in range(n_time_masks):\n","      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n","\n","    return aug_spec\n","\n","  @staticmethod\n","  def getSpectrogramFromSound(sound_path, sr, channel, duration, shift_pct):\n","    sound = SoundUtils.open(sound_path)\n","    sound = SoundUtils.resample(sound, sr)\n","    sound = SoundUtils.rechannel(sound, channel)\n","    sound = SoundUtils.pad_trunc(sound, duration)\n","    sound = SoundUtils.time_shift(sound, shift_pct)\n","    sound = SoundUtils.spectro_gram(sound, n_mels=64, n_fft=1024, hop_len=None)\n","    sound = SoundUtils.spectro_augment(sound, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n","    return sound\n","\n","  @staticmethod\n","  def getSpectrogramFromSoundAndSampleRate(sound, sr, channel, duration, shift_pct):\n","    sound = SoundUtils.resample(sound, sr)\n","    sound = SoundUtils.rechannel(sound, channel)\n","    sound = SoundUtils.pad_trunc(sound, duration)\n","    sound = SoundUtils.time_shift(sound, shift_pct)\n","    sound = SoundUtils.spectro_gram(sound, n_mels=64, n_fft=1024, hop_len=None)\n","    sound = SoundUtils.spectro_augment(sound, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n","    return sound"],"metadata":{"id":"_kyVi3yw0nNG","executionInfo":{"status":"ok","timestamp":1648903928168,"user_tz":-120,"elapsed":14,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#@title Prepare data for sound cnn. {display-mode: \"form\"}\n","#@markdown\n","#@markdown You do not need to look into this cell.\n","#@markdown Just execute once and you are good to go.\n","\n","#-------------------------------------------------------------------------------\n","# Preparation of data and helper functions.\n","#-------------------------------------------------------------------------------\n","\n","class SoundCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        conv_layers = []\n","\n","        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","        self.relu1 = nn.ReLU()\n","        self.bn1 = nn.BatchNorm2d(8)\n","        init.kaiming_normal_(self.conv1.weight, a=0.1)\n","        self.conv1.bias.data.zero_()\n","        conv_layers += [self.conv1, self.relu1, self.bn1]\n","\n","        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        self.relu2 = nn.ReLU()\n","        self.bn2 = nn.BatchNorm2d(16)\n","        init.kaiming_normal_(self.conv2.weight, a=0.1)\n","        self.conv2.bias.data.zero_()\n","        conv_layers += [self.conv2, self.relu2, self.bn2]\n","\n","        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        self.relu3 = nn.ReLU()\n","        self.bn3 = nn.BatchNorm2d(32)\n","        init.kaiming_normal_(self.conv3.weight, a=0.1)\n","        self.conv3.bias.data.zero_()\n","        conv_layers += [self.conv3, self.relu3, self.bn3]\n","\n","        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        self.relu4 = nn.ReLU()\n","        self.bn4 = nn.BatchNorm2d(64)\n","        init.kaiming_normal_(self.conv4.weight, a=0.1)\n","        self.conv4.bias.data.zero_()\n","        conv_layers += [self.conv4, self.relu4, self.bn4]\n","\n","        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n","        self.lin = nn.Linear(in_features=64, out_features=10)\n","\n","        self.conv = nn.Sequential(*conv_layers)\n"," \n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.ap(x)\n","        x = x.view(x.shape[0], -1)\n","        x = self.lin(x)\n","        return x"],"metadata":{"id":"Jc4lYfWJ0pSa","executionInfo":{"status":"ok","timestamp":1648903928661,"user_tz":-120,"elapsed":504,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# MOUNT GDRIVE\n","Mount gdrive to connect to local folders/files"],"metadata":{"id":"hrwV5ee4Aiai"}},{"cell_type":"code","source":["drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5c83L8JVANrO","executionInfo":{"status":"ok","timestamp":1648903946890,"user_tz":-120,"elapsed":18240,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}},"outputId":"faba60cd-befb-4fa4-e96c-82911730719f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["# LOAD MODEL\n","Use the gpu device with pytorch to load the model"],"metadata":{"id":"b02G_Y6aAnOC"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","state_dict = torch.load('gdrive/My Drive/Colab Notebooks/Progetto/digits_speach_model.pth')\n","sound_model = SoundCNN().to(device)\n","sound_model.load_state_dict(state_dict['model_state_dict'])\n","sound_model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"940AwDz4ADhC","executionInfo":{"status":"ok","timestamp":1648903957653,"user_tz":-120,"elapsed":10772,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}},"outputId":"fc67ce0f-319c-452c-c652-e3bf322effe8"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SoundCNN(\n","  (conv1): Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","  (relu1): ReLU()\n","  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (relu2): ReLU()\n","  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (relu3): ReLU()\n","  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (relu4): ReLU()\n","  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (ap): AdaptiveAvgPool2d(output_size=1)\n","  (lin): Linear(in_features=64, out_features=10, bias=True)\n","  (conv): Sequential(\n","    (0): Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","    (1): ReLU()\n","    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (4): ReLU()\n","    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (7): ReLU()\n","    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (10): ReLU()\n","    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# EXAMPLE OF PREDICTION\n","Load a sound from RECORDING and predict it"],"metadata":{"id":"ewMpwlxiAxKD"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","spectrogram = SoundUtils.getSpectrogramFromSound(\"gdrive/My Drive/Colab Notebooks/RECORDINGS/01/2_01_1.wav\", 48000, 2, 1000, 0.1)\n","outputs = sound_model(spectrogram[None, ...].cuda())\n","_, predicted = torch.max(outputs, 1)\n","print(f\"Value predicted: {predicted.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZaxH9K4p1pA","executionInfo":{"status":"ok","timestamp":1648903965656,"user_tz":-120,"elapsed":8041,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}},"outputId":"0764ec19-bafb-426d-d4a2-64ee237f0159"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Value predicted: 2\n"]}]},{"cell_type":"markdown","source":["#RECORDING OWN VOICE\n","Using the microphone of browser throut Google Colab, I record the audio"],"metadata":{"id":"5IFUPXiWv4oK"}},{"cell_type":"code","source":["!pip install ffmpeg-python > /dev/null"],"metadata":{"id":"rQfiGBbPnZln","executionInfo":{"status":"ok","timestamp":1648903970357,"user_tz":-120,"elapsed":4710,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#@title Prepare utilities for sound record functions. {display-mode: \"form\"}\n","#@markdown\n","#@markdown You do not need to look into this cell.\n","#@markdown Just execute once and you are good to go.\n","\n","#@markdown Code taken from https://ricardodeazambuja.com/deep_learning/2019/03/09/audio_and_video_google_colab/\n","\n","#-------------------------------------------------------------------------------\n","# Preparation of data and helper functions.\n","#-------------------------------------------------------------------------------\n","from IPython.display import HTML, Audio\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","import io\n","import ffmpeg\n","import tempfile\n","import pathlib\n","\n","\n","AUDIO_HTML = \"\"\"\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n","\"\"\"\n","\n","def get_audio():\n","  display(HTML(AUDIO_HTML))\n","  data = eval_js(\"data\")\n","  binary = b64decode(data.split(',')[1])\n","  \n","  process = (ffmpeg\n","    .input('pipe:0')\n","    .output('pipe:1', format='wav')\n","    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n","  )\n","  output, err = process.communicate(input=binary)\n","  \n","  riff_chunk_size = len(output) - 8\n","  # Break up the chunk size into four bytes, held in b.\n","  q = riff_chunk_size\n","  b = []\n","  for i in range(4):\n","      q, r = divmod(q, 256)\n","      b.append(r)\n","\n","  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n","  riff = output[:4] + bytes(b) + output[8:]\n","\n","  with tempfile.TemporaryDirectory() as tmpdirname:\n","    path = pathlib.Path(tmpdirname) / 'tmp.wav'\n","    with open(path, 'wb') as f:\n","       f.write(riff)\n","       \n","    x, sr = torchaudio.load(path)\n","\n","  return x, sr"],"metadata":{"id":"bLYAM3EacgCH","executionInfo":{"status":"ok","timestamp":1648903971041,"user_tz":-120,"elapsed":706,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["sound = get_audio()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98},"id":"RTvbW_i3i_kz","executionInfo":{"status":"ok","timestamp":1648904012796,"user_tz":-120,"elapsed":6547,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}},"outputId":"8601ce11-c56c-4e8b-879c-a558b6223433"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };            \n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# MODEL FOR PREDICTION\n","Using the model trained, I can predict the number recorded from microphone before"],"metadata":{"id":"Yg3O5dpvwMsZ"}},{"cell_type":"code","source":["spectr = SoundUtils.getSpectrogramFromSoundAndSampleRate(sound, 48000, 2, 1000, 0.1)\n","out = sound_model(spectr[None, ...].cuda())\n","_, pr = torch.max(out, 1)\n","print(f\"Value predicted: {pr.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5mDEuUC3D_Y_","executionInfo":{"status":"ok","timestamp":1648904036961,"user_tz":-120,"elapsed":6,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}},"outputId":"54f46784-eacd-4a16-a3af-1a46d7b1afac"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Value predicted: 1\n"]}]}]}