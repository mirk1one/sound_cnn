{"cells":[{"cell_type":"markdown","metadata":{"id":"mFUJ6URY1MHV"},"source":["Data: https://www.kaggle.com/datasets/sripaadsrinivasan/audio-mnist"]},{"cell_type":"markdown","metadata":{"id":"WPAClxcmBvVD"},"source":["# IMPORT PACKAGES\n","All package that are imported for the solution of the problem"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wOCGfUx_B2H-"},"outputs":[],"source":["import os\n","import math\n","import random\n","import pandas as pd\n","import time\n","from sklearn.metrics import confusion_matrix\n","import torch\n","from torch import optim\n","from torch.autograd import Variable\n","import torch.nn as nn\n","from torch.nn import init\n","from torch.utils.data import DataLoader, Dataset, random_split\n","import torchaudio\n","from torchaudio import transforms\n","from google.colab import drive"]},{"cell_type":"markdown","metadata":{"id":"9rnBqstjipZj"},"source":["# MOUNT GDRIVE\n","Mount gdrive to connect to local folders/files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14385,"status":"ok","timestamp":1648845648799,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"},"user_tz":-120},"id":"HR6DJUloir0f","outputId":"b9b35021-130c-4b4c-c991-d302e926b5b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"voyuXnFw15RZ"},"outputs":[],"source":["#@title Prepare utilities for sound functions. {display-mode: \"form\"}\n","#@markdown\n","#@markdown You do not need to look into this cell.\n","#@markdown Just execute once and you are good to go.\n","\n","#-------------------------------------------------------------------------------\n","# Preparation of data and helper functions.\n","#-------------------------------------------------------------------------------\n","\n","class SoundUtils():\n","  \n","  @staticmethod\n","  def open(audio_file):\n","    sig, sr = torchaudio.load(audio_file)\n","    return (sig, sr)\n","\n","  @staticmethod\n","  def rechannel(aud, new_channel):\n","    sig, sr = aud\n","    if (sig.shape[0] == new_channel):\n","      return aud\n","    if (new_channel == 1):\n","      resig = sig[:1, :]\n","    else:\n","      resig = torch.cat([sig, sig])\n","    return ((resig, sr))\n","\n","  @staticmethod\n","  def resample(aud, newsr):\n","    sig, sr = aud\n","    if (sr == newsr):\n","      return aud\n","    num_channels = sig.shape[0]\n","    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n","    if (num_channels > 1):\n","      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n","      resig = torch.cat([resig, retwo])\n","    return ((resig, newsr))\n","\n","  @staticmethod\n","  def pad_trunc(aud, max_ms):\n","    sig, sr = aud\n","    num_rows, sig_len = sig.shape\n","    max_len = sr//1000 * max_ms\n","\n","    if (sig_len > max_len):\n","      sig = sig[:,:max_len]\n","\n","    elif (sig_len < max_len):\n","      pad_begin_len = random.randint(0, max_len - sig_len)\n","      pad_end_len = max_len - sig_len - pad_begin_len\n","      pad_begin = torch.zeros((num_rows, pad_begin_len))\n","      pad_end = torch.zeros((num_rows, pad_end_len))\n","      sig = torch.cat((pad_begin, sig, pad_end), 1)\n","    return (sig, sr)\n","\n","  @staticmethod\n","  def time_shift(aud, shift_limit):\n","    sig,sr = aud\n","    _, sig_len = sig.shape\n","    shift_amt = int(random.random() * shift_limit * sig_len)\n","    return (sig.roll(shift_amt), sr)\n","\n","  @staticmethod\n","  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n","    sig,sr = aud\n","    top_db = 80\n","    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n","    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n","    return (spec)\n","  \n","  @staticmethod\n","  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n","    _, n_mels, n_steps = spec.shape\n","    mask_value = spec.mean()\n","    aug_spec = spec\n","\n","    freq_mask_param = max_mask_pct * n_mels\n","    for _ in range(n_freq_masks):\n","      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n","\n","    time_mask_param = max_mask_pct * n_steps\n","    for _ in range(n_time_masks):\n","      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n","\n","    return aug_spec\n","\n","  @staticmethod\n","  def getSpectrogramFromSound(sound_path, sr, channel, duration, shift_pct):\n","    sound = SoundUtils.open(sound_path)\n","    sound = SoundUtils.resample(sound, sr)\n","    sound = SoundUtils.rechannel(sound, channel)\n","    sound = SoundUtils.pad_trunc(sound, duration)\n","    sound = SoundUtils.time_shift(sound, shift_pct)\n","    sound = SoundUtils.spectro_gram(sound, n_mels=64, n_fft=1024, hop_len=None)\n","    sound = SoundUtils.spectro_augment(sound, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n","    return sound\n","\n","  @staticmethod\n","  def getSpectrogramFromSoundAndSampleRate(sound, sr, channel, duration, shift_pct):\n","    sound = SoundUtils.resample(sound, sr)\n","    sound = SoundUtils.rechannel(sound, channel)\n","    sound = SoundUtils.pad_trunc(sound, duration)\n","    sound = SoundUtils.time_shift(sound, shift_pct)\n","    sound = SoundUtils.spectro_gram(sound, n_mels=64, n_fft=1024, hop_len=None)\n","    sound = SoundUtils.spectro_augment(sound, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n","    return sound"]},{"cell_type":"markdown","metadata":{"id":"2wUzPUXQCKAm"},"source":["# LOAD DEVICE\n","Load the torch device to use the gpu instead of the cpu (important to connected the gpu runtime)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1648845649239,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"},"user_tz":-120},"id":"YFzGI7gWCM5h","outputId":"a9e8d160-4b47-42b4-c56e-b17831014113"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n","Tesla K80\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","if torch.cuda.is_available():\n","  print(torch.cuda.get_device_name(0))"]},{"cell_type":"markdown","metadata":{"id":"ZVc9Yz9v3NLj"},"source":["# DATASET SOUND CLASS\n","Definition of a custom Pytorch Dataset object, to use it for loading data from folder and get an item. It is a custom Dataset that use the audio transforms to preprocess an audio file and prepare every items in it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FOyu-XnP3MiM"},"outputs":[],"source":["class DigitsSoundDataset(Dataset):\n","  def __init__(self, data_path, num_folders, num_sounds):\n","    self.data_path = data_path\n","    self.num_folders = num_folders\n","    self.num_sounds = num_sounds\n","\n","    self.sr = 48000\n","    self.channel = 2\n","    self.duration = 1000\n","    self.shift_pct = 0.1\n","            \n","  def __len__(self):\n","    return self.num_sounds\n","    \n","  def __getitem__(self, idx):\n","    folder = idx // (self.num_sounds // self.num_folders)\n","    label = (idx - folder * (self.num_sounds // self.num_folders)) // (self.num_sounds // (self.num_folders * 10))\n","    elem = (idx - folder * (self.num_sounds // self.num_folders)) - (label * (self.num_sounds // self.num_folders // 10))\n","\n","    sound_file = os.path.join(self.data_path, f\"{folder+1:02d}\", f\"{label}_{folder+1:02d}_{elem}.wav\")\n","\n","    sound = SoundUtils.getSpectrogramFromSound(sound_file, self.sr, self.channel, self.duration, self.shift_pct)\n","\n","    return sound, label"]},{"cell_type":"markdown","metadata":{"id":"AqmBFyNsCsyD"},"source":["# LOAD DATASETS\n","Given the names of the guys that record the digits, I get the training and the test sets of the sounds, that are tensor arrays. Training set will be the 80% of sounds, test set will be remaining 20% of sounds."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KF18roYNSm7N"},"outputs":[],"source":["dataset = DigitsSoundDataset(\"gdrive/My Drive/Colab Notebooks/RECORDINGS/\", 60, 30000) #60, 30000\n","num_ds = len(dataset)\n","num_train = round(num_ds * 0.8)\n","num_test = num_ds - num_train\n","training_set, test_set = random_split(dataset, [num_train, num_test])"]},{"cell_type":"markdown","metadata":{"id":"qD0x3ooeD970"},"source":["# SET DATALOADERS\n","Creation of the loaders to train and test the network, they use the custom Dataset object to get individual data items and packages them into batch of data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TfGZVHtXEIQn"},"outputs":[],"source":["train_dataloader = DataLoader(training_set, batch_size=40, shuffle=True)\n","test_dataloader = DataLoader(test_set, batch_size=40, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"CRtu__2lUV8c"},"source":["# BUILD THE CNN MODEL\n","Definition of the convolutional neural network of sound. Is defined to build a CNN classification architecture to process them. It has 4 convolutional layers that generate the feature map. These data are reshaped in a format that we can use like an input of a linear classifier layer, which give in output the predictions of the 10 classes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4vU5uouUY3x"},"outputs":[],"source":["class SoundCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        conv_layers = []\n","\n","        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","        self.relu1 = nn.ReLU()\n","        self.bn1 = nn.BatchNorm2d(8)\n","        init.kaiming_normal_(self.conv1.weight, a=0.1)\n","        self.conv1.bias.data.zero_()\n","        conv_layers += [self.conv1, self.relu1, self.bn1]\n","\n","        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        self.relu2 = nn.ReLU()\n","        self.bn2 = nn.BatchNorm2d(16)\n","        init.kaiming_normal_(self.conv2.weight, a=0.1)\n","        self.conv2.bias.data.zero_()\n","        conv_layers += [self.conv2, self.relu2, self.bn2]\n","\n","        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        self.relu3 = nn.ReLU()\n","        self.bn3 = nn.BatchNorm2d(32)\n","        init.kaiming_normal_(self.conv3.weight, a=0.1)\n","        self.conv3.bias.data.zero_()\n","        conv_layers += [self.conv3, self.relu3, self.bn3]\n","\n","        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        self.relu4 = nn.ReLU()\n","        self.bn4 = nn.BatchNorm2d(64)\n","        init.kaiming_normal_(self.conv4.weight, a=0.1)\n","        self.conv4.bias.data.zero_()\n","        conv_layers += [self.conv4, self.relu4, self.bn4]\n","\n","        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n","        self.lin = nn.Linear(in_features=64, out_features=10)\n","\n","        self.conv = nn.Sequential(*conv_layers)\n"," \n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.ap(x)\n","        x = x.view(x.shape[0], -1)\n","        x = self.lin(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8687,"status":"ok","timestamp":1648845658613,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"},"user_tz":-120},"id":"NMhIQpOrU7qJ","outputId":"632b267e-862a-4265-b1f6-7e54f7e5b304"},"outputs":[{"output_type":"stream","name":"stdout","text":["SoundCNN(\n","  (conv1): Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","  (relu1): ReLU()\n","  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (relu2): ReLU()\n","  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (relu3): ReLU()\n","  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (relu4): ReLU()\n","  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (ap): AdaptiveAvgPool2d(output_size=1)\n","  (lin): Linear(in_features=64, out_features=10, bias=True)\n","  (conv): Sequential(\n","    (0): Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","    (1): ReLU()\n","    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (4): ReLU()\n","    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (7): ReLU()\n","    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (10): ReLU()\n","    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n",")\n"]}],"source":["sound_model = SoundCNN().to(device)\n","next(sound_model.parameters()).device\n","print(sound_model)"]},{"cell_type":"markdown","metadata":{"id":"3F6GlsW1daya"},"source":["# LOSS FUNCTION\n","Definition of the loss function, where it will be the cross entropy loss."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1648845658614,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"},"user_tz":-120},"id":"e55yXT94dcbx","outputId":"e6467d63-92d2-4287-86d5-d469458faf73"},"outputs":[{"output_type":"stream","name":"stdout","text":["CrossEntropyLoss()\n"]}],"source":["loss_function = nn.CrossEntropyLoss()\n","print(loss_function)"]},{"cell_type":"markdown","metadata":{"id":"bNMALg0rfBit"},"source":["# OPTIMIZATION OF REGULARIZATION\n","Definition of the function of optimization of regularization, that it will be the Adam function."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1648845658615,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"},"user_tz":-120},"id":"5JmkTk0lfEiD","outputId":"5f340389-a4d4-46f5-9f17-5a6dd7120bdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    eps: 1e-08\n","    lr: 0.001\n","    weight_decay: 0\n",")\n"]}],"source":["optimizer = optim.Adam(sound_model.parameters(), lr=0.001)\n","print(optimizer)"]},{"cell_type":"markdown","metadata":{"id":"Iqb5XF9XhpdE"},"source":["# TRAIN THE NETWORK\n","After the definitions of loss and optimizer functions to dynamically vary our learning rate as training progresses, I will define the train function. It is trained for epochs, processing a batch of data in every iteration. Then we track the accuracy, the loss and the time for every part of batch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uaJXxn2fhsDG"},"outputs":[],"source":["def train(num_epoch, cnn, train_loader):\n","  cnn.train()\n","  t = time.time()\n","\n","  for epoch in range(num_epoch):\n","      running_loss = 0.0\n","      correct_prediction = 0\n","      total_prediction = 0\n","\n","      for i, data in enumerate(train_loader):\n","          inputs = Variable(data[0]).to(device)\n","          labels = Variable(data[1]).to(device)\n","\n","          outputs = cnn(inputs)\n","          loss = loss_function(outputs, labels)\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","\n","          running_loss += loss.item()\n","\n","          _, prediction = torch.max(outputs,1)\n","          \n","          correct_prediction += (prediction == labels).sum().item()\n","          total_prediction += prediction.shape[0]\n","\n","          if((i+1) % 20 == 0):\n","            num_batches = len(train_loader)\n","            avg_loss = running_loss / num_batches\n","            acc = correct_prediction/total_prediction\n","            elapsed = time.time() - t\n","            print(f'Epoch: [{epoch+1}/{num_epoch}], Batch: [{i+1}/{len(train_loader)}], Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}, Time: {elapsed:.1f}')\n","            t = time.time()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PWaBIrV_kt9I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648855738361,"user_tz":-120,"elapsed":10079752,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}},"outputId":"d44d5a04-6aa1-4057-fbc4-7d43d7f8ba28"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: [1/10], Batch: [20/600], Loss: 0.08, Accuracy: 0.16, Time: 322.6\n","Epoch: [1/10], Batch: [40/600], Loss: 0.15, Accuracy: 0.21, Time: 293.7\n","Epoch: [1/10], Batch: [60/600], Loss: 0.21, Accuracy: 0.26, Time: 296.5\n","Epoch: [1/10], Batch: [80/600], Loss: 0.28, Accuracy: 0.29, Time: 293.1\n","Epoch: [1/10], Batch: [100/600], Loss: 0.34, Accuracy: 0.32, Time: 294.3\n","Epoch: [1/10], Batch: [120/600], Loss: 0.39, Accuracy: 0.35, Time: 291.9\n","Epoch: [1/10], Batch: [140/600], Loss: 0.44, Accuracy: 0.37, Time: 291.5\n","Epoch: [1/10], Batch: [160/600], Loss: 0.49, Accuracy: 0.40, Time: 291.0\n","Epoch: [1/10], Batch: [180/600], Loss: 0.54, Accuracy: 0.42, Time: 290.3\n","Epoch: [1/10], Batch: [200/600], Loss: 0.58, Accuracy: 0.45, Time: 288.6\n","Epoch: [1/10], Batch: [220/600], Loss: 0.62, Accuracy: 0.47, Time: 288.2\n","Epoch: [1/10], Batch: [240/600], Loss: 0.66, Accuracy: 0.49, Time: 288.3\n","Epoch: [1/10], Batch: [260/600], Loss: 0.69, Accuracy: 0.51, Time: 289.5\n","Epoch: [1/10], Batch: [280/600], Loss: 0.72, Accuracy: 0.52, Time: 286.1\n","Epoch: [1/10], Batch: [300/600], Loss: 0.75, Accuracy: 0.54, Time: 284.3\n","Epoch: [1/10], Batch: [320/600], Loss: 0.78, Accuracy: 0.56, Time: 285.2\n","Epoch: [1/10], Batch: [340/600], Loss: 0.81, Accuracy: 0.57, Time: 290.1\n","Epoch: [1/10], Batch: [360/600], Loss: 0.83, Accuracy: 0.58, Time: 289.4\n","Epoch: [1/10], Batch: [380/600], Loss: 0.86, Accuracy: 0.59, Time: 287.3\n","Epoch: [1/10], Batch: [400/600], Loss: 0.88, Accuracy: 0.61, Time: 288.7\n","Epoch: [1/10], Batch: [420/600], Loss: 0.90, Accuracy: 0.62, Time: 287.7\n","Epoch: [1/10], Batch: [440/600], Loss: 0.92, Accuracy: 0.63, Time: 289.0\n","Epoch: [1/10], Batch: [460/600], Loss: 0.94, Accuracy: 0.64, Time: 288.5\n","Epoch: [1/10], Batch: [480/600], Loss: 0.96, Accuracy: 0.65, Time: 287.1\n","Epoch: [1/10], Batch: [500/600], Loss: 0.97, Accuracy: 0.66, Time: 288.0\n","Epoch: [1/10], Batch: [520/600], Loss: 0.99, Accuracy: 0.66, Time: 285.7\n","Epoch: [1/10], Batch: [540/600], Loss: 1.01, Accuracy: 0.67, Time: 284.1\n","Epoch: [1/10], Batch: [560/600], Loss: 1.02, Accuracy: 0.68, Time: 285.1\n","Epoch: [1/10], Batch: [580/600], Loss: 1.03, Accuracy: 0.69, Time: 285.0\n","Epoch: [1/10], Batch: [600/600], Loss: 1.05, Accuracy: 0.70, Time: 284.4\n","Epoch: [2/10], Batch: [20/600], Loss: 0.01, Accuracy: 0.90, Time: 5.2\n","Epoch: [2/10], Batch: [40/600], Loss: 0.02, Accuracy: 0.91, Time: 5.2\n","Epoch: [2/10], Batch: [60/600], Loss: 0.04, Accuracy: 0.91, Time: 5.2\n","Epoch: [2/10], Batch: [80/600], Loss: 0.05, Accuracy: 0.92, Time: 5.2\n","Epoch: [2/10], Batch: [100/600], Loss: 0.06, Accuracy: 0.92, Time: 5.2\n","Epoch: [2/10], Batch: [120/600], Loss: 0.07, Accuracy: 0.92, Time: 5.2\n","Epoch: [2/10], Batch: [140/600], Loss: 0.08, Accuracy: 0.92, Time: 5.5\n","Epoch: [2/10], Batch: [160/600], Loss: 0.09, Accuracy: 0.92, Time: 5.2\n","Epoch: [2/10], Batch: [180/600], Loss: 0.10, Accuracy: 0.92, Time: 5.2\n","Epoch: [2/10], Batch: [200/600], Loss: 0.11, Accuracy: 0.92, Time: 5.3\n","Epoch: [2/10], Batch: [220/600], Loss: 0.12, Accuracy: 0.92, Time: 5.2\n","Epoch: [2/10], Batch: [240/600], Loss: 0.12, Accuracy: 0.92, Time: 5.2\n","Epoch: [2/10], Batch: [260/600], Loss: 0.13, Accuracy: 0.92, Time: 5.3\n","Epoch: [2/10], Batch: [280/600], Loss: 0.14, Accuracy: 0.92, Time: 5.3\n","Epoch: [2/10], Batch: [300/600], Loss: 0.15, Accuracy: 0.93, Time: 5.2\n","Epoch: [2/10], Batch: [320/600], Loss: 0.16, Accuracy: 0.93, Time: 5.2\n","Epoch: [2/10], Batch: [340/600], Loss: 0.17, Accuracy: 0.93, Time: 5.2\n","Epoch: [2/10], Batch: [360/600], Loss: 0.17, Accuracy: 0.93, Time: 5.2\n","Epoch: [2/10], Batch: [380/600], Loss: 0.18, Accuracy: 0.93, Time: 5.2\n","Epoch: [2/10], Batch: [400/600], Loss: 0.19, Accuracy: 0.93, Time: 5.1\n","Epoch: [2/10], Batch: [420/600], Loss: 0.19, Accuracy: 0.93, Time: 5.2\n","Epoch: [2/10], Batch: [440/600], Loss: 0.20, Accuracy: 0.93, Time: 5.2\n","Epoch: [2/10], Batch: [460/600], Loss: 0.20, Accuracy: 0.93, Time: 5.1\n","Epoch: [2/10], Batch: [480/600], Loss: 0.21, Accuracy: 0.94, Time: 5.3\n","Epoch: [2/10], Batch: [500/600], Loss: 0.22, Accuracy: 0.94, Time: 5.2\n","Epoch: [2/10], Batch: [520/600], Loss: 0.22, Accuracy: 0.94, Time: 5.2\n","Epoch: [2/10], Batch: [540/600], Loss: 0.23, Accuracy: 0.94, Time: 5.2\n","Epoch: [2/10], Batch: [560/600], Loss: 0.23, Accuracy: 0.94, Time: 5.3\n","Epoch: [2/10], Batch: [580/600], Loss: 0.24, Accuracy: 0.94, Time: 5.2\n","Epoch: [2/10], Batch: [600/600], Loss: 0.24, Accuracy: 0.94, Time: 5.2\n","Epoch: [3/10], Batch: [20/600], Loss: 0.01, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [40/600], Loss: 0.01, Accuracy: 0.95, Time: 5.2\n","Epoch: [3/10], Batch: [60/600], Loss: 0.02, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [80/600], Loss: 0.02, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [100/600], Loss: 0.03, Accuracy: 0.96, Time: 5.3\n","Epoch: [3/10], Batch: [120/600], Loss: 0.03, Accuracy: 0.95, Time: 5.3\n","Epoch: [3/10], Batch: [140/600], Loss: 0.04, Accuracy: 0.96, Time: 5.3\n","Epoch: [3/10], Batch: [160/600], Loss: 0.04, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [180/600], Loss: 0.05, Accuracy: 0.96, Time: 5.1\n","Epoch: [3/10], Batch: [200/600], Loss: 0.05, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [220/600], Loss: 0.06, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [240/600], Loss: 0.06, Accuracy: 0.96, Time: 5.4\n","Epoch: [3/10], Batch: [260/600], Loss: 0.06, Accuracy: 0.96, Time: 5.4\n","Epoch: [3/10], Batch: [280/600], Loss: 0.07, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [300/600], Loss: 0.07, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [320/600], Loss: 0.08, Accuracy: 0.96, Time: 5.3\n","Epoch: [3/10], Batch: [340/600], Loss: 0.08, Accuracy: 0.96, Time: 5.3\n","Epoch: [3/10], Batch: [360/600], Loss: 0.09, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [380/600], Loss: 0.09, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [400/600], Loss: 0.09, Accuracy: 0.96, Time: 5.3\n","Epoch: [3/10], Batch: [420/600], Loss: 0.10, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [440/600], Loss: 0.10, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [460/600], Loss: 0.11, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [480/600], Loss: 0.11, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [500/600], Loss: 0.11, Accuracy: 0.96, Time: 5.2\n","Epoch: [3/10], Batch: [520/600], Loss: 0.12, Accuracy: 0.96, Time: 5.1\n","Epoch: [3/10], Batch: [540/600], Loss: 0.12, Accuracy: 0.96, Time: 5.1\n","Epoch: [3/10], Batch: [560/600], Loss: 0.12, Accuracy: 0.97, Time: 5.2\n","Epoch: [3/10], Batch: [580/600], Loss: 0.13, Accuracy: 0.97, Time: 5.1\n","Epoch: [3/10], Batch: [600/600], Loss: 0.13, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [20/600], Loss: 0.00, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [40/600], Loss: 0.01, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [60/600], Loss: 0.01, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [80/600], Loss: 0.01, Accuracy: 0.97, Time: 5.0\n","Epoch: [4/10], Batch: [100/600], Loss: 0.02, Accuracy: 0.97, Time: 5.2\n","Epoch: [4/10], Batch: [120/600], Loss: 0.02, Accuracy: 0.97, Time: 5.0\n","Epoch: [4/10], Batch: [140/600], Loss: 0.02, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [160/600], Loss: 0.03, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [180/600], Loss: 0.03, Accuracy: 0.97, Time: 5.2\n","Epoch: [4/10], Batch: [200/600], Loss: 0.03, Accuracy: 0.97, Time: 5.2\n","Epoch: [4/10], Batch: [220/600], Loss: 0.04, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [240/600], Loss: 0.04, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [260/600], Loss: 0.04, Accuracy: 0.97, Time: 5.4\n","Epoch: [4/10], Batch: [280/600], Loss: 0.05, Accuracy: 0.97, Time: 5.2\n","Epoch: [4/10], Batch: [300/600], Loss: 0.05, Accuracy: 0.97, Time: 5.2\n","Epoch: [4/10], Batch: [320/600], Loss: 0.05, Accuracy: 0.97, Time: 5.2\n","Epoch: [4/10], Batch: [340/600], Loss: 0.05, Accuracy: 0.97, Time: 5.2\n","Epoch: [4/10], Batch: [360/600], Loss: 0.06, Accuracy: 0.97, Time: 5.2\n","Epoch: [4/10], Batch: [380/600], Loss: 0.06, Accuracy: 0.97, Time: 5.2\n","Epoch: [4/10], Batch: [400/600], Loss: 0.07, Accuracy: 0.97, Time: 5.2\n","Epoch: [4/10], Batch: [420/600], Loss: 0.07, Accuracy: 0.97, Time: 5.2\n","Epoch: [4/10], Batch: [440/600], Loss: 0.07, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [460/600], Loss: 0.07, Accuracy: 0.97, Time: 5.0\n","Epoch: [4/10], Batch: [480/600], Loss: 0.08, Accuracy: 0.97, Time: 5.0\n","Epoch: [4/10], Batch: [500/600], Loss: 0.08, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [520/600], Loss: 0.08, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [540/600], Loss: 0.08, Accuracy: 0.97, Time: 5.0\n","Epoch: [4/10], Batch: [560/600], Loss: 0.09, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [580/600], Loss: 0.09, Accuracy: 0.97, Time: 5.1\n","Epoch: [4/10], Batch: [600/600], Loss: 0.09, Accuracy: 0.97, Time: 5.1\n","Epoch: [5/10], Batch: [20/600], Loss: 0.00, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [40/600], Loss: 0.01, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [60/600], Loss: 0.01, Accuracy: 0.98, Time: 5.3\n","Epoch: [5/10], Batch: [80/600], Loss: 0.01, Accuracy: 0.98, Time: 5.0\n","Epoch: [5/10], Batch: [100/600], Loss: 0.01, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [120/600], Loss: 0.02, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [140/600], Loss: 0.02, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [160/600], Loss: 0.02, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [180/600], Loss: 0.02, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [200/600], Loss: 0.02, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [220/600], Loss: 0.03, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [240/600], Loss: 0.03, Accuracy: 0.98, Time: 5.4\n","Epoch: [5/10], Batch: [260/600], Loss: 0.03, Accuracy: 0.98, Time: 5.2\n","Epoch: [5/10], Batch: [280/600], Loss: 0.04, Accuracy: 0.98, Time: 5.3\n","Epoch: [5/10], Batch: [300/600], Loss: 0.04, Accuracy: 0.98, Time: 5.0\n","Epoch: [5/10], Batch: [320/600], Loss: 0.04, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [340/600], Loss: 0.04, Accuracy: 0.98, Time: 5.0\n","Epoch: [5/10], Batch: [360/600], Loss: 0.05, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [380/600], Loss: 0.05, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [400/600], Loss: 0.05, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [420/600], Loss: 0.05, Accuracy: 0.98, Time: 5.2\n","Epoch: [5/10], Batch: [440/600], Loss: 0.05, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [460/600], Loss: 0.06, Accuracy: 0.98, Time: 5.0\n","Epoch: [5/10], Batch: [480/600], Loss: 0.06, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [500/600], Loss: 0.06, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [520/600], Loss: 0.06, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [540/600], Loss: 0.06, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [560/600], Loss: 0.07, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [580/600], Loss: 0.07, Accuracy: 0.98, Time: 5.1\n","Epoch: [5/10], Batch: [600/600], Loss: 0.07, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [20/600], Loss: 0.00, Accuracy: 0.97, Time: 5.1\n","Epoch: [6/10], Batch: [40/600], Loss: 0.01, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [60/600], Loss: 0.01, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [80/600], Loss: 0.01, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [100/600], Loss: 0.01, Accuracy: 0.98, Time: 5.0\n","Epoch: [6/10], Batch: [120/600], Loss: 0.01, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [140/600], Loss: 0.02, Accuracy: 0.98, Time: 5.2\n","Epoch: [6/10], Batch: [160/600], Loss: 0.02, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [180/600], Loss: 0.02, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [200/600], Loss: 0.02, Accuracy: 0.98, Time: 5.0\n","Epoch: [6/10], Batch: [220/600], Loss: 0.02, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [240/600], Loss: 0.03, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [260/600], Loss: 0.03, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [280/600], Loss: 0.03, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [300/600], Loss: 0.03, Accuracy: 0.98, Time: 5.2\n","Epoch: [6/10], Batch: [320/600], Loss: 0.03, Accuracy: 0.98, Time: 5.0\n","Epoch: [6/10], Batch: [340/600], Loss: 0.04, Accuracy: 0.98, Time: 5.0\n","Epoch: [6/10], Batch: [360/600], Loss: 0.04, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [380/600], Loss: 0.04, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [400/600], Loss: 0.04, Accuracy: 0.98, Time: 5.2\n","Epoch: [6/10], Batch: [420/600], Loss: 0.05, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [440/600], Loss: 0.05, Accuracy: 0.98, Time: 5.1\n","Epoch: [6/10], Batch: [460/600], Loss: 0.05, Accuracy: 0.98, Time: 5.3\n","Epoch: [6/10], Batch: [480/600], Loss: 0.05, Accuracy: 0.98, Time: 5.2\n","Epoch: [6/10], Batch: [500/600], Loss: 0.05, Accuracy: 0.98, Time: 5.2\n","Epoch: [6/10], Batch: [520/600], Loss: 0.05, Accuracy: 0.98, Time: 5.2\n","Epoch: [6/10], Batch: [540/600], Loss: 0.06, Accuracy: 0.98, Time: 5.2\n","Epoch: [6/10], Batch: [560/600], Loss: 0.06, Accuracy: 0.98, Time: 5.2\n","Epoch: [6/10], Batch: [580/600], Loss: 0.06, Accuracy: 0.98, Time: 5.2\n","Epoch: [6/10], Batch: [600/600], Loss: 0.06, Accuracy: 0.98, Time: 5.2\n","Epoch: [7/10], Batch: [20/600], Loss: 0.00, Accuracy: 0.98, Time: 5.3\n","Epoch: [7/10], Batch: [40/600], Loss: 0.00, Accuracy: 0.99, Time: 5.2\n","Epoch: [7/10], Batch: [60/600], Loss: 0.01, Accuracy: 0.98, Time: 5.1\n","Epoch: [7/10], Batch: [80/600], Loss: 0.01, Accuracy: 0.98, Time: 5.0\n","Epoch: [7/10], Batch: [100/600], Loss: 0.01, Accuracy: 0.98, Time: 5.1\n","Epoch: [7/10], Batch: [120/600], Loss: 0.01, Accuracy: 0.98, Time: 5.1\n","Epoch: [7/10], Batch: [140/600], Loss: 0.01, Accuracy: 0.98, Time: 5.1\n","Epoch: [7/10], Batch: [160/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [180/600], Loss: 0.02, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [200/600], Loss: 0.02, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [220/600], Loss: 0.02, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [240/600], Loss: 0.02, Accuracy: 0.99, Time: 5.0\n","Epoch: [7/10], Batch: [260/600], Loss: 0.02, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [280/600], Loss: 0.02, Accuracy: 0.99, Time: 5.2\n","Epoch: [7/10], Batch: [300/600], Loss: 0.03, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [320/600], Loss: 0.03, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [340/600], Loss: 0.03, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [360/600], Loss: 0.03, Accuracy: 0.99, Time: 5.2\n","Epoch: [7/10], Batch: [380/600], Loss: 0.03, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [400/600], Loss: 0.03, Accuracy: 0.99, Time: 5.2\n","Epoch: [7/10], Batch: [420/600], Loss: 0.04, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [440/600], Loss: 0.04, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [460/600], Loss: 0.04, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [480/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n","Epoch: [7/10], Batch: [500/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n","Epoch: [7/10], Batch: [520/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n","Epoch: [7/10], Batch: [540/600], Loss: 0.04, Accuracy: 0.99, Time: 5.1\n","Epoch: [7/10], Batch: [560/600], Loss: 0.05, Accuracy: 0.99, Time: 5.0\n","Epoch: [7/10], Batch: [580/600], Loss: 0.05, Accuracy: 0.99, Time: 5.0\n","Epoch: [7/10], Batch: [600/600], Loss: 0.05, Accuracy: 0.99, Time: 5.2\n","Epoch: [8/10], Batch: [20/600], Loss: 0.00, Accuracy: 0.98, Time: 5.1\n","Epoch: [8/10], Batch: [40/600], Loss: 0.00, Accuracy: 0.99, Time: 5.1\n","Epoch: [8/10], Batch: [60/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [8/10], Batch: [80/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [8/10], Batch: [100/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [8/10], Batch: [120/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [8/10], Batch: [140/600], Loss: 0.01, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [160/600], Loss: 0.01, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [180/600], Loss: 0.01, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [200/600], Loss: 0.02, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [220/600], Loss: 0.02, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [240/600], Loss: 0.02, Accuracy: 0.99, Time: 5.1\n","Epoch: [8/10], Batch: [260/600], Loss: 0.02, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [280/600], Loss: 0.02, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [300/600], Loss: 0.02, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [320/600], Loss: 0.02, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [340/600], Loss: 0.02, Accuracy: 0.99, Time: 5.1\n","Epoch: [8/10], Batch: [360/600], Loss: 0.03, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [380/600], Loss: 0.03, Accuracy: 0.99, Time: 4.9\n","Epoch: [8/10], Batch: [400/600], Loss: 0.03, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [420/600], Loss: 0.03, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [440/600], Loss: 0.03, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [460/600], Loss: 0.03, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [480/600], Loss: 0.04, Accuracy: 0.99, Time: 5.1\n","Epoch: [8/10], Batch: [500/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [520/600], Loss: 0.04, Accuracy: 0.99, Time: 5.1\n","Epoch: [8/10], Batch: [540/600], Loss: 0.04, Accuracy: 0.99, Time: 5.1\n","Epoch: [8/10], Batch: [560/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n","Epoch: [8/10], Batch: [580/600], Loss: 0.04, Accuracy: 0.99, Time: 5.1\n","Epoch: [8/10], Batch: [600/600], Loss: 0.04, Accuracy: 0.99, Time: 5.4\n","Epoch: [9/10], Batch: [20/600], Loss: 0.00, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [40/600], Loss: 0.00, Accuracy: 0.99, Time: 5.0\n","Epoch: [9/10], Batch: [60/600], Loss: 0.00, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [80/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [100/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [120/600], Loss: 0.01, Accuracy: 0.99, Time: 5.0\n","Epoch: [9/10], Batch: [140/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [160/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [180/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [200/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [220/600], Loss: 0.02, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [240/600], Loss: 0.02, Accuracy: 0.99, Time: 5.0\n","Epoch: [9/10], Batch: [260/600], Loss: 0.02, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [280/600], Loss: 0.02, Accuracy: 0.99, Time: 5.2\n","Epoch: [9/10], Batch: [300/600], Loss: 0.02, Accuracy: 0.99, Time: 5.2\n","Epoch: [9/10], Batch: [320/600], Loss: 0.02, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [340/600], Loss: 0.02, Accuracy: 0.99, Time: 5.0\n","Epoch: [9/10], Batch: [360/600], Loss: 0.02, Accuracy: 0.99, Time: 5.0\n","Epoch: [9/10], Batch: [380/600], Loss: 0.03, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [400/600], Loss: 0.03, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [420/600], Loss: 0.03, Accuracy: 0.99, Time: 5.0\n","Epoch: [9/10], Batch: [440/600], Loss: 0.03, Accuracy: 0.99, Time: 5.0\n","Epoch: [9/10], Batch: [460/600], Loss: 0.03, Accuracy: 0.99, Time: 5.2\n","Epoch: [9/10], Batch: [480/600], Loss: 0.03, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [500/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n","Epoch: [9/10], Batch: [520/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n","Epoch: [9/10], Batch: [540/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n","Epoch: [9/10], Batch: [560/600], Loss: 0.04, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [580/600], Loss: 0.04, Accuracy: 0.99, Time: 5.1\n","Epoch: [9/10], Batch: [600/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n","Epoch: [10/10], Batch: [20/600], Loss: 0.00, Accuracy: 0.99, Time: 5.0\n","Epoch: [10/10], Batch: [40/600], Loss: 0.00, Accuracy: 0.99, Time: 5.1\n","Epoch: [10/10], Batch: [60/600], Loss: 0.00, Accuracy: 0.99, Time: 5.1\n","Epoch: [10/10], Batch: [80/600], Loss: 0.01, Accuracy: 0.99, Time: 5.0\n","Epoch: [10/10], Batch: [100/600], Loss: 0.01, Accuracy: 0.99, Time: 5.0\n","Epoch: [10/10], Batch: [120/600], Loss: 0.01, Accuracy: 0.99, Time: 5.2\n","Epoch: [10/10], Batch: [140/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [10/10], Batch: [160/600], Loss: 0.01, Accuracy: 0.99, Time: 5.2\n","Epoch: [10/10], Batch: [180/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [10/10], Batch: [200/600], Loss: 0.01, Accuracy: 0.99, Time: 5.1\n","Epoch: [10/10], Batch: [220/600], Loss: 0.01, Accuracy: 0.99, Time: 5.2\n","Epoch: [10/10], Batch: [240/600], Loss: 0.01, Accuracy: 0.99, Time: 5.5\n","Epoch: [10/10], Batch: [260/600], Loss: 0.02, Accuracy: 0.99, Time: 5.3\n","Epoch: [10/10], Batch: [280/600], Loss: 0.02, Accuracy: 0.99, Time: 5.2\n","Epoch: [10/10], Batch: [300/600], Loss: 0.02, Accuracy: 0.99, Time: 5.2\n","Epoch: [10/10], Batch: [320/600], Loss: 0.02, Accuracy: 0.99, Time: 5.2\n","Epoch: [10/10], Batch: [340/600], Loss: 0.02, Accuracy: 0.99, Time: 5.2\n","Epoch: [10/10], Batch: [360/600], Loss: 0.02, Accuracy: 0.99, Time: 5.2\n","Epoch: [10/10], Batch: [380/600], Loss: 0.02, Accuracy: 0.99, Time: 5.3\n","Epoch: [10/10], Batch: [400/600], Loss: 0.02, Accuracy: 0.99, Time: 5.3\n","Epoch: [10/10], Batch: [420/600], Loss: 0.03, Accuracy: 0.99, Time: 5.2\n","Epoch: [10/10], Batch: [440/600], Loss: 0.03, Accuracy: 0.99, Time: 5.1\n","Epoch: [10/10], Batch: [460/600], Loss: 0.03, Accuracy: 0.99, Time: 5.0\n","Epoch: [10/10], Batch: [480/600], Loss: 0.03, Accuracy: 0.99, Time: 5.1\n","Epoch: [10/10], Batch: [500/600], Loss: 0.03, Accuracy: 0.99, Time: 5.1\n","Epoch: [10/10], Batch: [520/600], Loss: 0.03, Accuracy: 0.99, Time: 5.0\n","Epoch: [10/10], Batch: [540/600], Loss: 0.03, Accuracy: 0.99, Time: 5.0\n","Epoch: [10/10], Batch: [560/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n","Epoch: [10/10], Batch: [580/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n","Epoch: [10/10], Batch: [600/600], Loss: 0.04, Accuracy: 0.99, Time: 5.0\n"]}],"source":["num_epoch = 10\n","train(num_epoch, sound_model, train_dataloader)"]},{"cell_type":"markdown","metadata":{"id":"jTtGxcF9xVBf"},"source":["# CHECK HOW NETWORK BEHAVIES IN TEST SET\n","Finally to check the evalutation of the metric, i will do an inference loop removing the updating of the gradient, then I use the CNN to see if the predicted value is the same of the test label. Also I can build the confusion matrix to understand if the prediction it will be good or not, seeing if the values on the diagonal are very high and in the others are near to 0.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E9aItXAkxbAA","executionInfo":{"status":"ok","timestamp":1648857889282,"user_tz":-120,"elapsed":2150958,"user":{"displayName":"Mirko Gualducci","userId":"01140278991727090850"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f0ec9d40-30c6-473a-a298-11a55ca7b465"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[620,   0,   2,   2,   2,   1,   0,   1,   0,   0],\n","       [  0, 564,   2,   1,   2,   1,   0,   0,   0,   7],\n","       [  1,   0, 553,   2,   0,   0,   1,   1,   0,   0],\n","       [  0,   0,   2, 583,   0,   1,   1,   0,   1,   0],\n","       [  0,   0,   2,   1, 592,   2,   0,   0,   0,   0],\n","       [  0,   0,   0,   0,   2, 558,   0,   3,   0,   1],\n","       [  0,   0,   0,   0,   0,   1, 619,   1,   4,   0],\n","       [  1,   0,   1,   0,   2,   2,   0, 616,   0,   1],\n","       [  0,   0,   1,   1,   0,   2,   0,   0, 610,   0],\n","       [  0,   1,   1,   1,   0,   5,   0,   0,   0, 618]])"]},"metadata":{},"execution_count":14}],"source":["actual_labels_test = []\n","predictes_labels_test = []\n","sound_model.to('cpu')\n","\n","with torch.no_grad():\n","  for data in test_dataloader:\n","    inputs = data[0]\n","    labels = data[1]\n","    test_output = sound_model(inputs)\n","    pred_y = torch.max(test_output,1)[1].data.squeeze()\n","    actual_labels_test += labels.tolist()\n","    predictes_labels_test += pred_y.tolist()\n","\n","confusion_matrix(actual_labels_test, predictes_labels_test)"]},{"cell_type":"markdown","metadata":{"id":"1_2fijM7y57x"},"source":["# SAVE MODEL\n","I save the model, to reuse it in other applications."]},{"cell_type":"code","source":["torch.save({\n","  'epoch': num_epoch,\n","  'model_state_dict': sound_model.state_dict(),\n","  'optimizer_state_dict': optimizer.state_dict()\n","  }, 'gdrive/My Drive/Colab Notebooks/Progetto/digits_speach_model.pth')"],"metadata":{"id":"qPinpaKwvCPb"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"digits_speach_model.ipynb","provenance":[],"mount_file_id":"1QgkDmrjxhnA4iN1apYh6azO67Tyyvtwm","authorship_tag":"ABX9TyPSZoPwC8NAUIz3RQ7EWzOU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}